#!/usr/bin/python

import os  # required to call youtube-upload
import requests  # required for download direct links
from selenium import webdriver  # required for scrape inspect links
from bs4 import BeautifulSoup as bs  # required for scrape inspect links
import random  # reqiured for dynamic names
import re  # required for transform to download links
import json  # python integrated json database
from collections import namedtuple  # python integrated json database
import datetime  # select weeknumber for title

def create_dependacies():
    try:
        os.mkdir("main-downloader-temp")
    except:
        print("dir 1 created")
    try:
        os.mkdir("main-downloader-temp/inspectlinks")
    except:
        print("dir 2 created")
    try:
        os.mkdir("main-downloader-temp/concat-list")
    except:
        print("dir 3 created")
    try:
        os.mkdir("main-downloader-temp/allcliprepo")
    except:
        print("dir 4 created")
    try:
        os.mkdir("main-downloader-temp/compiled-vids")
    except:
        print("dir 5 created")
    try:
        os.mkdir("main-downloader-temp/thumbnails")
    except:
        print("dir 6 created")
    try:
        os.mkdir("main-downloader-static")
        os.mkdir("main-downloader-static/thumbnails")
        #put all the thumbnails here /creator.capitalname
    except:
        print("dir 7 created")


def old__scrape_get_links_from_twitch_inspect_html2(scrapeurl):
    browser = webdriver.Firefox()  # replace with .Firefox(), or with the browser of your choice
    url = str(scrapeurl)
    browser.get(url)  # navigate to the page
    uglyhtml = browser.page_source
    browser.close()

    soup = bs(uglyhtml, "html.parser")
    psoup = bs.prettify(soup)

    pritiname = ("priti" + str(random.randint(10000, 99999)) + ".html")
    open(pritiname, "w").write(psoup)

    return (pritiname)
    # scrapes a page inspect elements and returns file name of the scrape output

    # consider setting up headless firefox
    # https://stackoverflow.com/questions/10399557/is-it-possible-to-run-selenium-firefox-web-driver-without-a-gui
    # using phantomJS aleady failed selenium does not support
    # using default on cli server with firefox isntalled didnt work
    # was unable to configure it as headlesss or headless using firefox

    # also mabye add a variable befor open() and use .close() after to prevent leaks ??


def scrape_get_links_from_twitch_inspect_html(scrapeurl):
    my_cwd = os.getcwd()
    dir1 = my_cwd + "/main-downloader-temp/inspectlinks/"

    # scrapeurl="https://www.twitch.tv/asmongold/clips?filter=clips&range=30d"
    options = webdriver.FirefoxOptions()
    options.headless = True
    browser = webdriver.Firefox(firefox_options=options)  # replace with .Firefox(), or with the browser of your choice
    url = str(scrapeurl)
    browser.get(url)  # navigate to the page
    uglyhtml = browser.page_source
    browser.close()

    soup = bs(uglyhtml, "html.parser")
    psoup = bs.prettify(soup)

    pritiname = (dir1 + "priti" + str(random.randint(10000, 99999)) + ".html")
    open(pritiname, "w").write(psoup)

    return (pritiname)


def scrape_transform_to_download_links(htmloftwitchinspect):
    beautifulscrape = htmloftwitchinspect
    read = open(beautifulscrape, "r").read()
    soup = bs(read, "html.parser")

    links1 = ""
    for link in soup.find_all("img"):
        links1 = str(links1) + str(link.get("src") + "\n")
    links1 = links1.splitlines()

    # scrapes links using regex:
    # . - any character that is not new line
    # * - repeat prievious option 0 or more times
    # ? - dont be greedy
    # 7C the start of constant strint
    # (.*) group1 collection inside () again select anything 0 or more times
    # \-p escape - key, follow up with p for a -p end of quirey
    # skip everything till the end line with .* as prieviously
    full_links = ""
    for link2 in links1:
        m = re.match(r".*?7C(.*)\-p.*", link2)
        if m != None:
            full_links = full_links + ("https://clips-media-assets2.twitch.tv/AT-cm%7C" + m.group(1) + ".mp4\n")
    full_links = full_links.splitlines()

    return full_links
    # returns array of downloadable links


def download_clip_files_return_location(path_to_direct_video_download):
    # download file to the locala system
    # also to return download location and file_title for the next command

    url = path_to_direct_video_download
    file_title = (url.split('/')[-1])
    # list = (os.popen("pwd").read())
    my_cwd = os.getcwd()
    # listmod = (list[:-1] + "/")
    local_filename = (my_cwd + "/main-downloader-temp/allcliprepo/" + file_title)

    r = requests.get(url)
    f = open(local_filename, 'wb')
    for chunk in r.iter_content(chunk_size=512 * 1024):
        if chunk:  # filter out keep-alive new chunks
            f.write(chunk)
    f.close()

    return local_filename, file_title
    # download files from specified links to curdir, and returms fullpath and title
    # mabye create option to ignore returning file title in output??
    # mabye send a variable parameter to create individual dir name


def transform_multiple_video_files(concat_list, who_im_scraping="twitchuser"):
    # MANDAORY requires all files as a list in order
    my_cwd = os.getcwd()
    dir2 = my_cwd + "/main-downloader-temp/concat-list/"
    dir3 = my_cwd + "/compiled-vids/"
    randd = random.randint(1000, 9999)
    videos_to_concat = concat_list
    video_list = videos_to_concat
    scraped_chanel = who_im_scraping  # temporary until added to function
    concat_outputfile = scraped_chanel + str(randd) + ".mp4"
    cononccc = (dir2 + "concat_list" + str(random.randint(10000, 99999)) + ".txt")  # ffmpeg script required file

    line_for_line = ""
    for video in video_list:
        # line_for_line = line_for_line + ("file "+ video + "\n" + "file ./empty.mp4\n" + "duration 1\n")
        line_for_line = line_for_line + ("file " + video + "\n")
    open(cononccc, "w").write(line_for_line)

    cmd = ("ffmpeg -f concat -safe 0 -i " + cononccc + " -c copy " + concat_outputfile)
    os.system(cmd)
    full_vid_location = dir3 + concat_outputfile

    return full_vid_location


def upload_final_product_to_youtube(path_to_local_video, video_title="notitle", description=""):
    cmd = ("youtube-upload " + path_to_local_video +
           " --title=" + video_title +
           " --description=" + description +
           " --category=entertainment")
    os.system(cmd)
    # use os.system to call youtube-upload
    # asuming youtube-upload is configured


def check_for_disabled_videos():
    # this will be ran after creating a full list of videos to concatenate,
    # before initialising the download
    # will accept integers and add a coment on the list of vide that caused the claim#
    print("hello world")


def glue_everything_and_upload(twitch_clip_page_link="https://something???", video_title="thitchvideo", description=""):
    func_link = str(twitch_clip_page_link)
    func_steamer = video_title

    out1 = scrape_get_links_from_twitch_inspect_html(func_link)
    out2 = scrape_transform_to_download_links(out1)
    hold_my_concat_list = ""
    for link in out2:
        file_location = download_clip_files_return_location(link)
        print("downloading " + link)
        hold_my_concat_list = hold_my_concat_list + (str(file_location[0]) + "\n")
    videos_to_concat = hold_my_concat_list.splitlines()

    path_to_vide_location = transform_multiple_video_files(videos_to_concat, func_steamer)
    print(path_to_vide_location)
    upload_final_product_to_youtube(path_to_vide_location, video_title, description)


def make_thumbnail(creatorUsername, titletext="demonamew2", weeknumber="14"):
    thumbnailpathexist=os.path.exists("main-downloader-static/thumbnails/" + creatorUsername)
    if thumbnailpathexist != True:
        return("")
    #variables mag for magickimage
    colors=["red", "blue", "magenta", "orchid", "teal", "yellow", "tomato", "forestgreen", "azure", "aqua", "blueviolet", "crimson", "fuchsia"]
    mag_bgcolor =random.choice(colors)
    mag_font = "Candice"
    mag_main_text=titletext
    mag_weeknumber=weeknumber
    mag_outputname1="main-downloader-temp/thumbnails/" + "thumbnail" + str(random.randint(10000, 99999))+".jpg"
    thumbdir=("main-downloader-static/thumbnails/" + creatorUsername)
    thumbdirlist=os.listdir(thumbdir)
    mag_faceimage=(thumbdir + "/" + random.choice(thumbdirlist))

    command0=("convert" +
        " -size 1280x720 " +
        " xc:" + mag_bgcolor +
        " -draw \"line 1,1 1,1\"" +
        " tempsave1.jpg"
        )

    command1 =(
        "convert" +
        " -font " + mag_font +
        " -fill white " +
        #attempt at merging image same command
        " -composite " + "tempsave1.jpg" +  # generated bg
        " " + mag_faceimage +        # face clip
        " -geometry 1280x720+150+75" +  # offset of face clip
        " -depth 8" +
        " -write tempsave2.jpg" +
        #first draw name
        " -pointsize 72 " +
        " -stroke black " +
        " -strokewidth 15 " +
        " -draw " + "'text 25,129 \"" + mag_main_text + "\"'" +
        " -stroke none " +
        " -draw " + "'text 25,129 \"" + mag_main_text + "\"'" +
        #second draw week number
        " -pointsize 310" +
        " -stroke black " +
        " -strokewidth 15 " +
        " -draw " + "'text 800,320 \"" + mag_weeknumber + "\"'" +
        " -stroke none " +
        " -draw " + "'text 800,320 \"" + mag_weeknumber + "\"'" +
        " " + mag_outputname1
        )
    mag_return1=(os.getcwd()+"/"+mag_outputname1)


    os.system(command0)
    os.system(command1)
    return(mag_return1)


if __name__ == '__main__':
    create_dependacies()
    week = datetime.date.today().strftime("%W")

    databasefile = """
        {
            "anita": {
              "username": "sweet_anita",
              "description": "Tourette legendary tic sweet anita dick fuck my bisquit dick banna overwatch ",
              "capsname":"Sweet Anita",
              "thumbnailtext":"",
              "thumbnailexist":""
              }
            ,

            "boaty":{
                "username":"b0aty",
                "description":"runescape deadman feminist warrior thick glasses dyed hair gay family friendly ",
                "capsname":"Gingerscaper B0ary",
                "thumbnailtext":"",
                "thumbnailexist":""
                }
            ,

            "asmongold": {
              "username": "asmongold",
              "description": "wow dark souls big dick twitch thot redneck bald stupid epic gamer meme review offensive dank meme compilation hilarious ",
              "capsname":"Asmongold",
              "thumbnailtext":"",
              "thumbnailexist":""
            }
        }
        """

    my_DB = json.loads(databasefile, object_hook=lambda d: namedtuple('X', d.keys())(*d.values()))

    for creator, creatordata in my_DB:
            generic_description = " best memes compilation v4 best memes compilation v21 lil tay  obunga gamecube memes best vines vines funny vines alia memes car salesman memes pewdiepie best memes compilation v24 dancing alien meme metal alien memes phil swift flex tape memes ninja  dame tu cosita memes despacito 2 tekashi 6ix9ine tekashi 6ix9ine memes momo zoom challenge zoom memes despacito memes minecraft memes super smash bros meme 6ix9ine ligma ligma ninja meme ligma memes  i came i saw meme ligma balls  in my feelings dance challenge keke challenge drake keke memes astroworld memes fefe roblox funny moments roblox memes smash memes supreme patty ksi deji memesjohny johny memes johny johny eating sugar blah blah blah memes Best Memes Compilation v26 Johny johny yes papa memes johny johnny yes papa best memes compilation v32 Thanos car johny johny memeselon musk lil pump kanye west roblox lil pump i love it memes thanos car memesspiderman memes eu memesbongo cat bongo cat memes tiktok cringe  moth memes  monky im monky  tiktok memes moth sans undertale memes spooky memes halloween memes tiktok cringe  tiktok memes best memes compilation v37 undertalebest memes compilation v38 steve harve"
            clip=("https://www.twitch.tv/" + creatordata[username] + "/clips?filter=clips&range=7d")
            titleorig=(creator.capsname + " top clips " + week)
            title=titleorig.replace(" ","\\ ")
            description=("top twitch clips daily " + creator.description + generic_description)
            description=description.replace(" ","\\ ")
            print(clip+"\n"+title+"\n"+description+"\n")
            thumbnail=make_thumbnail(creator.username,titleorig,week)
            print(thumbnail)
            #glue_everything_and_upload(clip,title,description)

    #
    # """
    #     "empty": {
    #       "username": "namegoeshere",
    #       "description": "description goes here",
    #       "capsname":"<++>",
    #       "thumbnailtext":"",
    #       "thumbnailexist":"n"
    #     }
    # """
